# LLM Provider Configuration
# Choose your LLM provider: "openai", "anthropic", "google", "litellm", or "auto"
LLM_PROVIDER=auto

# API Keys (only set the ones you plan to use)
OPENAI_API_KEY=your_open_ai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
GOOGLE_API_KEY=your_google_api_key_here

# Model Configuration (optional - will use defaults if not specified)
# OpenAI models: gpt-3.5-turbo, gpt-4, gpt-4-turbo, etc.
# Anthropic models: claude-3-sonnet-20240229, claude-3-haiku-20240307, etc.
# Google models: gemini-1.5-flash-latest, gemini-1.5-pro-latest, etc.
OPENAI_MODEL=gpt-3.5-turbo
ANTHROPIC_MODEL=claude-3-sonnet-20240229
GOOGLE_MODEL=gemini-1.5-flash-latest
LITELLM_MODEL=gpt-3.5-turbo

# Rate limiting (seconds between LLM calls)
LLM_MIN_INTERVAL=1.0

# Legacy support (will be used if LLM_PROVIDER=google or auto-detected)
# GOOGLE_API_KEY=your_google_api_key_here 